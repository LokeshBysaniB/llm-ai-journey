Different packages used as part of multiple small projects
1. **python-dotenv**: Loads environment variables from a `.env` file into your Python environment.
2. **jupyterlab**: A web-based interactive development environment for Jupyter notebooks, code, and data.
3. **ipywidgets**: Provides interactive widgets for Jupyter notebooks and the JupyterLab environment.
4. **requests**: Simple HTTP library for making network requests (GET, POST, etc.) in Python.
5. **numpy**: Core package for numerical computing in Python, providing support for large arrays and matrices.
6. **pandas**: Data manipulation and analysis library, offering data structures like DataFrames.
7. **scipy**: A library for scientific and technical computing, built on top of NumPy, with modules for optimization, integration, etc.
8. **scikit-learn**: Machine learning library providing simple tools for data analysis and model building.
9. **matplotlib**: A plotting library for creating static, animated, and interactive visualizations in Python.
10. **gensim**: Topic modeling and document similarity library, primarily for natural language processing (NLP).
11. **torch**: PyTorch, an open-source machine learning library focused on deep learning and tensor computation.
12. **transformers**: Hugging Face’s library for state-of-the-art natural language processing with pre-trained transformer models.
13. **tqdm**: Fast, extensible progress bar library for Python loops and functions.
14. **openai**: Python client library for interacting with OpenAI’s models (e.g., GPT, DALL-E).
15. **gradio**: A Python library for creating user interfaces for machine learning models, including web-based demos.
16. **langchain**: A framework for building applications with LLMs (Large Language Models), particularly for AI agents.
17. **tiktoken**: Tokenizer for OpenAI models (like GPT) to handle text encoding and tokenization efficiently.
18. **faiss-cpu**: Facebook’s AI Similarity Search library, optimized for efficient vector search and clustering on CPU.
19. **langchain-openai**: A LangChain extension for OpenAI models and APIs integration.
20. **langchain_experimental**: Experimental components in LangChain, likely for upcoming features.
21. **langchain_chroma**: LangChain integration with Chroma, a vector database for semantic search and retrieval.
22. **langchain[docarray]**: LangChain extension for integrating DocArray, a library for working with embeddings and vector search.
23. **datasets**: Hugging Face’s library for easily accessing and managing datasets for machine learning.
24. **sentencepiece**: Text tokenizer and detokenizer, typically used for NLP tasks, especially with transformer models.
25. **matplotlib (Duplicate)**: A plotting library for creating static, animated, and interactive visualizations.
26. **google-generativeai**: Python client for Google’s generative AI services like PaLM (Language Models).
27. **anthropic**: Library for working with Anthropic’s language models and AI tools.
28. **scikit-learn (Duplicate)**: Machine learning library providing simple tools for data analysis and model building.
29. **unstructured**: A library for unstructured data processing, including text extraction and analysis.
30. **chromadb**: A database designed for efficient similarity search and managing embeddings.
31. **plotly**: A graphing library for creating interactive visualizations and dashboards.
32. **jupyter-dash**: Integration of Dash (interactive web apps) with Jupyter Notebooks.
33. **beautifulsoup4**: A library for parsing HTML and XML documents, often used for web scraping.
34. **pydub**: A simple and easy-to-use library for audio file manipulation (e.g., conversion, cutting, etc.).
35. **modal**: Library for building serverless applications with Python.
36. **ollama**: Framework or library for building AI models or interacting with the Ollama API.
37. **accelerate**: Hugging Face library for optimizing training of machine learning models on different hardware.
38. **sentencepiece (Duplicate)**: Text tokenizer and detokenizer, typically used for NLP tasks.
39. **bitsandbytes**: Library for efficient deep learning, specifically focusing on memory and speed optimizations.
40. **psutil**: Cross-platform library for accessing system and process information like CPU, memory, and disk usage.
41. **setuptools**: A Python package used to build, package, and distribute Python projects.
42. **speedtest-cli**: A command-line tool for testing internet speed using Speedtest.net.
43. **sentence_transformers**: Library for sentence embeddings, useful for similarity search, clustering, and NLP tasks.
44. **feedparser**: A library for parsing RSS and Atom feeds in Python.
